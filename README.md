# Spider Archiver

Crawl and archive websites locally using [spider.cloud](https://spider.cloud). Browse saved pages in a VSCode-like interface with syntax highlighting.

![Spider Archiver â€” crawl and archive any website](./public/og.png)

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## License

This project is licensed under the [MIT license].

[MIT license]: https://github.com/spider-rs/spider-cloud-live-code-viewer/blob/main/LICENSE